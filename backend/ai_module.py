# backend/ai_module.py

import openai
import os
from dotenv import load_dotenv
from typing import List, Optional
import json
from pydantic import BaseModel, ConfigDict

# üîπ Carrega vari√°veis do .env com caminho expl√≠cito
dotenv_path = os.path.join(os.path.dirname(__file__), "..", ".env")
load_dotenv(dotenv_path)

# üîπ Define a chave da OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

# üîπ Fun√ß√£o para gerar explica√ß√µes com IA
def gerar_explicacao(pergunta: str) -> str:
    try:
        resposta = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um professor que explica de forma clara e objetiva para estudantes do ensino m√©dio."},
                {"role": "user", "content": f"Explique de forma clara: {pergunta}"}
            ],
            max_tokens=300,
            temperature=0.7
        )
        return resposta.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar explica√ß√£o: {str(e)}"

# üîπ Fun√ß√£o para gerar perguntas com base em uma mat√©ria e n√≠vel
def gerar_perguntas(materia: str, dificuldade: str = "f√°cil") -> List[str]:
    prompt = f"Crie 3 perguntas de m√∫ltipla escolha sobre {materia} com n√≠vel de dificuldade {dificuldade}, adequadas para ensino m√©dio."
    try:
        resposta = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um gerador de perguntas escolares."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.8
        )
        texto = resposta.choices[0].message.content.strip()
        perguntas = texto.split("\n\n") if "\n\n" in texto else texto.split("\n")
        return [p.strip() for p in perguntas if p.strip()]
    except Exception as e:
        return [f"Erro ao gerar perguntas: {str(e)}"]

# üîπ IA para gerar perguntas fixas por mat√©ria
def gerar_perguntas_por_materia(materia: str, dificuldade: str = "media") -> List[str]:
    perguntas = {
        "Matem√°tica": {
            "facil": ["Quanto √© 2 + 2?", "Qual √© o dobro de 5?"],
            "media": ["Resolva: 3x - 2 = 7", "Qual √© a √°rea de um quadrado de lado 4?"],
            "dificil": ["Derive a fun√ß√£o f(x) = 3x¬≤ + 2x", "Resolva a equa√ß√£o log(x) + log(2) = 1"]
        }
    }
    return perguntas.get(materia, {}).get(dificuldade, ["Pergunta n√£o encontrada para essa mat√©ria."])

# üîπ Fun√ß√£o para selecionar trecho liter√°rio
def selecionar_trecho_literatura() -> dict:
    trecho = (
        "Ningu√©m escreve para o outro. Escreve-se para preencher o vazio de si mesmo. "
        "Mas quando o outro se reconhece nesse vazio, nasce a literatura."
    )
    autor = "Mia Couto"
    perguntas = [
        "O que o autor quer dizer com 'preencher o vazio de si mesmo'?",
        "Como a literatura conecta o autor e o leitor nesse trecho?",
        "Voc√™ concorda com a ideia apresentada? Por qu√™?",
        "Interprete a frase: 'nasce a literatura'.",
        "Qual √© o tom emocional do trecho?"
    ]
    return {"autor": autor, "trecho": trecho, "perguntas": perguntas}

# üîπ Fun√ß√£o para gerar mensagens motivacionais
def gerar_mensagem_motivacional(resumo: str) -> str:
    try:
        resposta = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um coach motivacional que incentiva alunos com base no desempenho escolar."},
                {"role": "user", "content": f"Com base neste desempenho:\n{resumo}\nGere uma mensagem motivacional curta para o aluno."}
            ],
            max_tokens=100,
            temperature=0.7
        )
        return resposta.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar mensagem motivacional: {str(e)}"

# üîπ Fun√ß√£o para gerar resumos orientados
def gerar_resumo(texto: str, estilo: str) -> str:
    try:
        prompt = (
            f"Voc√™ √© um tutor de ensino m√©dio. "
            f"Pegue este texto e crie um resumo em formato {estilo}, "
            "destacando palavras-chave e levantando 2 perguntas de reflex√£o no final."
        )
        resposta = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": texto}
            ],
            temperature=0.5
        )
        return resposta.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar resumo: {str(e)}"

# üîπ Fun√ß√£o para gerar quizzes l√∫dicos
def gerar_quiz(materia: str, assunto: Optional[str], quantidade: int) -> List[dict]:
    topo = f"Crie {quantidade} perguntas de m√∫ltipla escolha sobre {materia}"
    if assunto:
        topo += f" (assunto espec√≠fico: {assunto})"
    prompt = (
        f"{topo}, adequadas para alunos do ensino m√©dio. "
        "Para cada pergunta, forne√ßa 4 op√ß√µes e marque qual √© a correta."
    )
    try:
        resp = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ gera quizzes educativos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8
        )
        texto = resp.choices[0].message.content.strip()
        return parse_quiz(texto)
    except Exception as e:
        return [{"error": str(e)}]

# üîπ Fun√ß√£o auxiliar para parsear o quiz
def parse_quiz(texto: str) -> List[dict]:
    try:
        return json.loads(texto)
    except json.JSONDecodeError:
        blocos = texto.split("\n\n")
        perguntas = []
        for bloco in blocos:
            linhas = [l.strip() for l in bloco.split("\n") if l.strip()]
            if not linhas:
                continue
            enunciado = linhas[0]
            opcoes = linhas[1:5]
            perguntas.append({"enunciado": enunciado, "opcoes": opcoes, "resposta_correta": opcoes[0] if opcoes else None})
        return perguntas

# üîπ Linha do Tempo (Hist√≥ria)
class TimelineRequest(BaseModel):
    periodo: str
    eventos: Optional[int] = 5

class EventoTimeline(BaseModel):
    data: str
    evento: str

class TimelineResponse(BaseModel):
    periodo: str
    eventos: List[EventoTimeline]
    model_config = ConfigDict(from_attributes=True)

# üîπ Fun√ß√£o para gerar linha do tempo hist√≥rica
def gerar_timeline(periodo: str, eventos: int) -> List[dict]:
    exemplos = {
        "Revolu√ß√£o Francesa": [
            {"data": "1789-07-14", "evento": "Queda da Bastilha"},
            {"data": "1789-08-26", "evento": "Declara√ß√£o dos Direitos do Homem"},
            {"data": "1791-09-03", "evento": "Primeira Constitui√ß√£o Francesa"},
            {"data": "1793-01-21", "evento": "Execu√ß√£o de Lu√≠s XVI"},
            {"data": "1799-11-09", "evento": "Golpe de 18 de Brum√°rio"}
        ]
    }
    return exemplos.get(periodo, [])[:eventos]


















